 Hello everyone, this is our tutorial video for Project 4 Donuts and as the old classic Duncan commercial said, it's time to make the donuts. So in this project video, I'm going to assume that you know a bit about the project from reading this back, we want to fill in some of the details and hints, etc. So my first big hint is this project has three parts, part A, MST, part B, fast, TSP, and part C, optimal, TSP. Now the part A, MST is a lecture, part C, the TSP, optimal TSP is part of the lecture called Backtracking Branch and Bound and TSP. Part B is not in lecture, you're going to have to do some good way about it and I'll give you some more tips on that when we get to talking about part B in particular. Now for all of the parts of this project, as with any of other projects, always watch for hints. When the auto-graders done running and it goes to the feedback page or if you go to look later on, you click on the timestamp and it shows you the feedback page, always search for the word hint. So this project has a lot of hints about correctness, not as many about time or memory, but a lot of hints about if you got this case wrong and then think about this, if you got these three test cases wrong, they probably all did the same wrong thing, think about that, etc. Now one thing about this project that's very different from other projects is that your output can be different from our output as long as it's valid output. So let's do a quick example. Let's say I'm working on part A, MST and I've got a really simple graph, there's four vertices, A square. Let's call them 0, 1, 2 and 3. And you look at the correct output and it says the total cost is 3.00. Well, that makes sense, there's three edges in it, each is looks like a unit cost and we list the edges as the edge from 1 to 2, the edge from 0 to 1 and the edge from 2 to 3. And you produce your output and it says 3.00, that's good, but then you have different edges, maybe you list 0, 1 first and then you list 0, 3 and then you list 2. So 0, 1, 0, 3 and you list not 2, 1, it would be 1, 2. And if we look at this, ours looks like this and 0, 1 and 2, 3 and yours looks like 0, 1 and 0, 3 and 1, 2. You say they look different, well that's okay, they're the same MST, they have the same cost, they both have three edges, they both have edges that are valid to produce a TSP, there's no isolated vertices that are unconnected, there's no cycles in it and that's basically what the judge, there's a program on the auto root greater called the judge that judges your output, it basically looks at the first thing is do these numbers match, if those don't match then you're wrong right there, it's definitely wrong. If those match then we go to the second step, we look at all of the edges of yours and we say hey, did these edges produce a connected graph with no cycles, does it produce a tree, if there's any cycles, if there's any unconnected vertices then you failed. The last thing we do is sum up the weights, the cost of these edges and we check does the sum of these costs is equal to the total that you report it and if all of those things are valid you've got a valid output and part B and C can be different from ours and still be valid. Another thing that's different about this project, there's a tool that we give you a link to in the projects back called the visualizer. So the visualizer allows you to say here's an input file, here's an output file and here's what mode it is and the modes are just either MST or TSP and it draws you a graph of what it looks like. One thing you might do is say hey, I'll load them in two different tabs of my browser. I'll have one tab with input and correct output, another tab with input and my output and I'll just toggle between them and look at them over the top of each other, do they look the same or at least really similar. Now in part B you could have really different results from ours and still be valid. So really for all of these the autograder is the ultimate judge but we've got some tools to help you along the way. Now let's talk about different parts separately, let's talk about part A and MST. Now for part A and MST we know it's an MST we need to decide which algorithm to use because two algorithms for solving MST. So it really comes down to is the graph dense, I want to use prim, is the graph sparse, I want to use cross goal. So let's think about it. So in our graph we have to have, draw this here, we have to have a border and then we've got the other parts of the x and y axis, I'm going to draw in black there. So the blue is all border including the origin and then the border separates the USA from Canada. So things in let's say the upper right are blue up here. So up in the upper right is Canada and then the other three regions are all USA. Now let's say that all the donut shops were in the USA. We just maybe we don't have a passport handy. So we're only going to go to donut shops in the USA. Well, if all the donut shops are in the USA then it's completely connected. If let's say they're all in the USA and maybe there's one on the border, that's still a completely connected graph. If it was the opposite, if everything was in Canada or all in Canada and a border or two it would be completely connected. What if it was mostly USA, one border and one in Canada? That would still be a really dense graph. We're only missing approximately V edges from Canada to the USA but the Canada to the border exists, border to USA exists, all the USA to each other exists, it's still a really dense graph. What if the number of donut shops was about equal? If the Canada here had about the same number of donut shops, well we'd still have to have a border in this case so that's about half Canada, about half USA plus one border. Well I'm going to claim that's still pretty dense. So how many edges are there? Well remember if I have V vertices, the number of edges is equal to V times V minus one over two. Now what if we considered just the vertices in Canada? If it's just the vertices in Canada then the number of vertices is V over two and the number of edges is equal to V over two times V over two minus one all over two which is approximately V squared over eight. The ones in the USA would be the same, approximately V squared over eight and if we add those up that's approximately V squared over four that's still a pretty dense graph. So if this is a dense graph we want to use Prim, we want to use the nested loop version of Prim and by nested loop I mean there's going to be an outer loop, four, five, four, four loop count is equal to zero, count is less than the number of vertices plus plus count. Why did I say count here instead of like I? Because we're not going to use count as an index. I've seen lots of people get this project wrong in part A, it's simple code but they tried to use the outer loop variable as an index and it's not. The outer loop is just going to count how many times we go through it. Then we're going to have a loop for step one which is find the smallest false one. Then step two is just going to be a liner two of code. Step two, not one. Step two is market as true. Wait, my pen lag there. Mark as true. And then there's going to be a loop for step three which is update the false neighbors. Code it this way. The other thing that's got to happen is before we do this we've got to mark somebody as a distance of zero. Pick anybody, vertex zero is the easiest because vertex zero always exists. So mark somebody as having a distance of zero. If you start saying I think I'll mark one as true outside the loop and then I know that it's vertex zero and I think I'll start with step three and then I'll do step it's easy to get it wrong. Don't change this. We gave you an algorithm in lecture. You start changing it. You say it's easy changes but it's also easy to get it wrong. So don't go reordering the parts. Don't try changing the overall algorithm. One thing you will notice though when looking at the algorithm is that Prim doesn't know anything about USA and Canada and borders and donuts. Not as Prim know whether two vertices are connected or not. The easiest way to do this is Prim doesn't know. Prim has a help. Think of me as your helper. You're writing the code for Prim. When you encounter the spot where you have to calculate the distance between two vertices you ask me. Okay, so let's throw a little example down here. I'll redraw my axes here. And let's put a few coordinates in here. I've got coordinates like A, B which is not actually on the border. I've got a C over here, D there and E up here. Okay, so if you ask me your helper what's the distance between A and B? I might say 4.3. You ask me about B to C. I say 15.8. You ask me about C to D. I might say 10.2. You ask me about D to E. I say at 6.8. But if you ask me about A to E I have to give you back a double. What should I say about A to E? I say infinity. And then you as Prim you don't even check if it's equal to infinity. You just go on and say hey, is this value that I just calculated better than what I've already got? No, okay, don't use it. And then the rest of the USA Canada border will all take care of itself. So as your helper you give me two coordinates, I give you a double. If those coordinates are USA Canada or Canada USA, I say infinity for anything else, I give you back a number. Now when you start categorizing it's a little bit too much time if the helper has to do the categorization. So as you read in the coordinates you could store an X and a Y and a category. Do not use pairs for this. Do not put a pair inside of a pair. Don't make a separate vector for the categorization. Just make a struct. Make a struct with names that make sense like row and column or X and Y, whatever you want to call it. Plus one for the category. The category would be USA, Canada or border. Ooh, great place for another E number of the clients. And so as you read them in, you categorize them. You say, well, wait a minute. The border only matters in part A. Is it okay if I store that category even when I'm on part B or C? Yep. I've written the code that way because a lot of people write it that way. I wrote my solution that way. It does fine on the memory. It does fine on time. Now when you do start categorizing them, be really careful about being too simple on the categorization because I've seen a lot of people who would say B is actually on the border. And it's not. B is not on the border. And you could get wrong answers if you think it is. D is on the border, B is not because B is on the black part in my drawing, but D is on the blue part. And the blue part does include the origin. So don't do anything to say if two donut shops have a distance of zero, it's invalid or I can't do it. It could happen. You know, there could be one building that has competing donut shops and they're basically the same X, Y coordinate. So don't look for it. Don't check for it. It could happen. The reason it could happen is because a lot of our input files were created by rolling up random numbers and sometimes the random numbers produce duplicates. So that's the real reason. The other thing you have to be really careful with, easy way to go wrong in part A is to be too simple with your calculations because of integer overflow. So the X's and Y's will always be integers. They don't have to be. It was just the easiest way to generate the numbers. But when you go to calculate a distance, if you say something like X1 minus X2 squared plus Y1 minus Y2 squared, it could overflow. The reason is you've taken the integers and subtracted them and then multiplied. Just another hint, a side hint. Don't use POW. So C++ doesn't have an exponentiation operator. It does have a POW function. Do not use POW. So POW, it takes too much time because it is too generic a function. It has to take negative 0.37 to the 0.591 power. And so it's got to be really general. Multiplication is going to be faster. You say, OK, well, I'll do X1 minus X2 times X1 minus X2. Well, the problem is if these are integers, 25k minus 25k is 50k. 50k times 50k is equal to negative 500 million in integer world. So if you do the subtraction, well, first of all, let's not do the subtraction twice. Let's do the subtraction, store it in the double, do the other subtraction, the Y1 minus Y2. Let's do that subtraction, store that in the double, do this subtraction, store this in a double. Multiply this times itself, multiply that times itself, the doubles when they get multiplied have a much bigger range than integers. So integers go up to like 2 billion. Doubles go up to approximately 10 to the 300 nth power. So lots safer. So just make sure you don't get bitten by the integer overflow problem. OK, so if that takes care of most of the stuff for part A. Now for part B and C, I'm going to give a few general tips and then we'll go on to separate tips for part B. So for part B and C, keep a vector, oops, VEC, keep a vector of indices. Now as indices, it could be int, it could be u int, 32 underscore t, either one side. And the reason you want to keep that vector of indices is that's what you have to print. When you're done producing your TSP, you've got to print the total and you've got to print a list of vertices names in order. And the vertices names are their indices. So when you print those, it's good if you had a vector that had those to begin with. I've seen a lot of students that try to make like a vector of pairs where it's an index and an index of a next one that are basically putting a linked list inside of a vector, painful to get it right, painful for part B to work with part C, just don't do it. Okay, I just remembered I'm going to have to go back just one minute because I forgot one thing to mention in part A. When you output your vertices for or your edges for part A, you always print small number followed by a large number. So even if you had the edge 3, 0, you would print it as 0, 3, or you had the edge 3, 2, you would print it as 2, 3. So always print the smallest one first. I just thought of that first. Second law is working on part B and C. Okay, so part B and C, we want to have a vector of indices is our basic data structure. Okay, so now let's talk about part B. So part B, which is the fast TSP, the idea here is, quick look ahead, part C optimal TSP is going to be OV factorial. If V gets beyond like 40, you can't wait for it. Part B is going to have like 40,000, 50,000 vertices. So in part B, we want to stick to algorithms that have O of V squared. We don't want to be any longer complexity than that. And what you're going to want to do is do a TSP heuristics. And look at a few of them, read about them, decide which one to implement. Don't be afraid to try more than one. These heuristics should not end up being more than like 30 to 50 lines. So if you have to throw away 30 lines of code and recode it, that's fine. So like I said, stick to things that are V squared, the simplest one is going to be greeting your snappin. Now all of these heuristics are going to be greedy. And they're greedy in different ways. They make their greedy decisions in different ways. So the simplest one is called greeting your snapper. Basically, you pick a starting point. Well, you don't get to pick a starting point. You've got to start at vertex zero. We've got to start at home and return to where we started. And we'll talk about why when we get to part C. So you always got to start with vertex zero. What greeting the nearest neighbor says is wherever vertex zero is, find the one closest to it. Like vertex seven is the closest one. That's who I go to next. And then whoever's closest to seven and not already true, oh, I got to keep track of who's true. So whoever's closest to seven and not already true gets picked as next. And we can just keep doing that whoever's closest to the most recent one. So if I went from like seven to one, so I went from zero to seven, seven to one, then I would go from one to the closest one. If the closest one happened to be over here at vertex three, I would go from one over to three. And then if the next closest false one was way over here at two, I would go from three to two. And this starts showing you why a greedy heuristic might not get the best answer. But this is how greeting your neighbor works. It's always like I'm growing a path. I had the path zero, then I had the path zero seven, then I go from seven to the closest false one. I had zero seven one, then I had zero seven, one, three, then I had zero seven, one, three, two, etc. So greeting your neighbor just grabs whoever's closest and not already true. Now greeting your neighbor does a fairly bad job. It'll also produce crossings, which I didn't do in here, but it'll produce crossings in the graph, which are which are bad choices. There's always a better choice if there's a crossing. And there's a part of the tutorial section called two opt. Two opt can basically be used to improve greeting your neighbor by trying to get rid of crossings. And it doesn't really look for crossings. It looks for choices of edges that could be different that would produce a smaller total. Now look at our tutorial section on two opt. If you implement two opt and you redux journal sources, you'll see a lot of external sources that have like a wild loop, a for loop, and a for loop. And this is v cubed and this is right out. You can't do v cubed. If you're going to do two opt, it's got to be a for loop and a for loop. Can't do more than that or you'll go over time. Now if you do greeting nearest neighbor, you have to do two opt to get decent answers. And greeting nearest neighbor plus two opt will get you almost all the points. In fact, it may be so close to all the points that you can't even see the difference. Like it'll say, you know, you got like one point that work. Like you got a 0.12 percent deduction and you got 1.76 out of 1.76. Because 0.12 percent with this number of digits, you can't even see it. So that's decent. But it's now two algorithms. You got to implement. You got your input greeting nearest neighbor and you got to implement two opt. So there's other heuristics that don't require two opt. So you could try a different heuristic. If you still can't get a short enough one, you've made a mistake somewhere in there. Because I've implemented for this like five different heuristics to make sure that all of the test cases, these five different heuristics all get either full points or greeting nearest neighbors. The only one that doesn't get full and it's really close. Also all of these are good enough to move on to part C. You might decide like, hey, I'm in this range here. You know, I could spend another day or two on a new heuristic or I could move on to part C because this is good enough to get all the points for part C. I verified that also. So then you could say, well, hey, I'm getting like 98 percent of the points for part B. Let's move on to part C and go get all those points. And then if I've got time, I'll come back and try a new heuristic for part B. That's a good approach too. Okay, so now we're going to talk about part C. So part C, which is optimal to SP, is going to be all of V factorial. Now one of the things that we were sticking in part B and C is that you must start at vertex zero. The real sort of measurement reason for this is that if I do every possible starting point, it's V factorial. But if I fix the starting point, then it's V minus one factorial. And when we're talking even a V of 30, V of 30 factorial is 30 times longer than 29 factorial. So really pragmatic reason to always have fixed starting point. And also it makes sense. You know, if I go from zero to one to three to five to four and back to zero, oh, I forgot to. So it's a three went to two and two went to five and five goes for zero. Whether I go from zero, one, three, two, five, four or I go to five, four, zero, one, three, it's still the same cycle. And whether I go around clockwise or counterclockwise, that doesn't matter either. So we want to make sure we always start at vertex zero. We need to know how to do that. We'll talk about that in a minute. If you look at the starter files that we gave you, one of the things that we gave you is called, I want to get my name right. I think it's called genperms.cpp.txt. And we put it in a text file just because it's a template. It really shouldn't be in a CPP file, but you know, we just gave it to you as text. So you'd have some place to copy and paste it from. So when you look at this, this has got a function called genperms, which we are going to talk about in lecture. But we'll end up with a little bit of duplicate effort here. The first thing to do when you start on part C and you take genperms is take it out of that text file and put it in your source code. Second thing is this is a recursive function. Not only is it recursive, it is non-tail recursive. Because it's not tail recursive, every function call has to go on stack. If you add parameters to genperms, like you're like, hey, I'm missing this. I'm missing that. I'm missing the other. If you start adding more and more parameters, all of those parameters have to be pushed onto the stack with every one of those v-1 factorial calls. So after you copy the genperms, you want to do two things. First, get rid of the path as a parameter. Make genperms a member function of a class and the path will be one of the member variables of the class. So what might we end up with in our class? Whatever we call it, we can call it part C for all I care. Part C class. So in my part C class, I might have my vertices that I read in. Like I have those somewhere. I've got to have my current path. I've got to have my current path cost. I've got to have my best path. I've got to have my best cost. So there's like five member variables that we're not adding to genperms parameter list and we're speeding things up. So genperms should really have one parameter. So genperms should have one parameter, which is, you know, the race that it add up here, we want to end up with genperms just has one parameter, size t, per length. We'll talk about what that means in a minute, but we want to have just one parameter in there. And to do that, we want to make this part of a class. If you say, oh, I don't need a class, I can just make a bunch of global variables. That's the project you do not want to show to a prospective employer. Because when they see that the only way you can code things is with global variables, that makes you unattractive as an employee. Because a 400 500 line program, if somebody, some function modifies the global variable that shouldn't have, you can track it down. And a program with a million lines of code where someone just accidentally modified a global variable when they thought they were modifying a local variable, they just forgot to declare the global variable. The names happen to be the same. Whole project is broken. Go find the bug. Oh, well, since we noticed the bug, 18 people have checked in 47 files. Comprising 57,000 lines of code that we've got to go through. It's just not worth it. So don't use global variables as a crutch, make a class, make member variables, make member functions. So gen programs will be a member function and promising that we're going to talk about in lecture is going to be another member function. So the perm length, what it means is it tells us how many of the vertices are fixed and how many are still able to be changed. Think of it as the permanent length. So let's do a little example. Let's say my path variable right now has 0, 5, 2, 1, 4, 3, and perm length is 2. What that means is that those two are fixed and the 2, 1, 4, 3 can still be permuted. Now the algorithm and the function as a whole is going to try every permutation. But at this point in time, 0 and 5 are permanent, 2, 1, 4, and 3 can be changed around in different configurations. So that's what perm length means. Now I also set up here what is path cost? It's the cost so far. So at this point in time, what would be in path cost would be the edge from 0 to 5. The cost of that would be in path cost right now. So when we start out, the very first time we call gen programs, two things should be true. Path cost should start out at 0.0. There are no edges. At perm length, should start out, the very first call should be gen programs of 1. So when we call it with gen programs of 1, let's do a little bit of racing here. So when gen programs is 1, what that means is this variable is fixed. It is permanent and it cannot be changed. What else is up for grabs? We're going to go through all of the five factorial other permutations of 5, 2, 1, 4, 3, 4, 5, 2, 1, 3, 4, 5, 2, 1, 3, 4, 5, 2, etc. We're going to go through all of those. So that's how we make sure that the vertex 0 is always at the beginning. So the other thing that has to be true before you call this is 0 must be the first thing in the path. You can start with any order for the rest of these and it will get the right answer. The order of these could matter though for speed. Think about why? Think about what it could be in there. Now we've got to go back to the other member of it. The best cost and the best path. These are the best ones we've ever seen. Now I could start out with the best path is empty and the best cost is infinity. And we would get the right answer. But it would be too slow because everything would look promising. So instead of doing that, before we call Genperms for the first time, let's get something in here that's better than I don't know and infinity. Let's call part B. Let's call part B and whatever part B gives us, that's the best cost I've ever seen. That's the best path I've ever seen. You must memorize both. If you memorize one of them and part B gets lucky and gets the right answer, you'll have a total with an empty best path vector because part C will never improve upon it. So we don't want that. We've got to call part B and remember both parts of it are my best I've ever seen. And then we can start calling the Genperms. In the Genperms that we gave you, it's a skeleton. It's the basics that must be there to even start getting permutations, right? The things that you have to do are you've got to add the code that keeps this current path cost updated. With each recursive call to Genperms, you should be adding something to the total and after the recursive call, you should take it away from the total. Think of preconditions, post-conditions. Before I called Genperms for the first time, the total was zero. And I add the edge length, let's say 2.7. I add the edge 2.7 to it. When it's done, my total has to go back to zero and then I try a different edge. And I add that one, I make a recursive call, when the recursive call is done, I take that edge cost out of the total. So everything you add, you must take away. That's the first big change on the next big change we've got to make. So right before and after the recursive calls, add the cost of the new edge. Like right here, it would be the edge from zero to five would be what we'd have to add and what we'd have to take away. Think about where it is. It's in path sub perm length and path sub something else. So this is a subscript that we can use. When we get to the base case, the Genperms has a base case at the top because it's recursive function. God, I have a base case. The base case is when perm length is equal to path dot size. So when we get up to the point where perm length is six and path dot size has six vertices in it, that's when we're in the base case. Everything is permanent. Nothing is up for rearrangement. And what you've got to do is add some code to say, is this new proposed cycle better than the best I've ever seen? Make sure to close the cycle because as you make the recursive calls, we're going to add the edge from zero to five, the edge from five to two to one, one to four, four to three, and then we get to a recursive call. Or sorry, we get to the recursive call. That's the base case. In the base case, path cost right now has in it. We go up to the top here. Path cost has in it. My pen stopped working here. Oh, there it goes. It just caught up to me all the time. My path cost right now has zero five plus five to plus two one plus one four plus four three. That's five edges. Five edges six vertices. A cycle better have six edges. I'm missing the edge from three back to zero. I'm missing the closing edge. So in the base case, you've got to add the closing edge. Then check if it's better. Whether it's if it's better, then you update the best cost and the best path to be equal to the current path and the current cost. Before you return, you must take this closing edge out of the cost. Pre-conditions, post-conditions. Before the base case, there were five edges in the total. When the base case is done, we better be back to five edges in the total and not six. Okay, another thing that we're going to need to do is we got to speed things up a little bit. So the way that we're going to speed things up is the promising function. Promising is supposed to answer the question. Is this look like a good way to start? So let's do a little example. And I started to do one kind of like this before. Let's say, let's do a simple one. Okay, so my graph has 12 vertices. And I just so happen to start connecting them in numerical order. So I connect zero to one and one to two and two to three and three to four and four to five. Now I ask, does this look like a good way to make an efficient cycle of these 12 vertices? No, it doesn't look like it. Well we need a numerical way to calculate looking good. And that's where promising comes in. So what promising has to do is take the fixed edges and then estimate the remaining edges and decide whether it looks good. And I just realized I did this in the wrong color to stay consistent with the slides. I'll do a little bit of that. Okay, so in the slides, I think my tablet's lagging a little bit. There we go. Okay, so in the slides, we have black for the current path. So let's say as gen-premises running, I add this edge and this edge and this edge and promising keeps saying true, but eventually it's going to say false. Let's say I've got that and I call promising. What promising has to say is, well, let's see, I've got five edges so far, a cycle of these 12 vertices would have 12 edges. I need seven new edges. Now I've got four edges so far. The cycle would have 12. I need to estimate eight new edges. Now where can I get an estimate of those eight new edges? Well, I could produce the MST of the unvisited ones. Now the slides used gray for the MST. I'm going to use green because it start both start with G. So I might produce the MST of these and say that's the green portion. Now I don't have quite enough edges yet because that was six edges. I need eight in my estimate. The other two edges would be from the beginning of the path to the unvisited and from the end of the path to the unvisited. These edges must be the smallest possible. So I've got to connect zero to the unvisited. I've got to connect vertex four to the unvisited and these are in the blue is what's in the lecture slides. So I would connect from well zero to the closest unvisited to zero. It doesn't look like it's closer to, I didn't number these vertices, so six, seven, eight, nine, ten, eleven. So of these unvisited vertices, five, six, seven, eight, nine, ten, eleven, who looks like they're the closest to zero, let's say it looks like five. It's a judgment call. I'll say zero is closest to five. Of all of the unvisited, the closest one to zero is five. And four, the closest one to four is obviously six. So that would be what promising has to do. Promising has to find those green edges in the MST, find those two blue connecting edges. And then if I add the black plus the blue plus the gray green, that I compare that to my best I've ever seen. And if that is less than the best I've ever seen, it looks promising. If it's greater than or equal to the best I've ever seen, it does not look promising. So that's the numerical way of doing it. What if you say, well, I don't think zero and five are the closest. I think the one closest to zero is also vertex six. Well, that's fine. You can connect vertex zero to vertex six and connect four to six. It's not a cycle. It's an estimate of a numeric total. And this numeric total must be less than or equal to reality. Lecture'll tell you why. So this is why parts, this is another reason why we wanted to code them in order A, B, C. Because part C, we want to call part B to get our best I've ever seen. And we want to call part A to get the MST. Now, when you start doing this, you might say, hey, my part A works perfectly. I'm just going to call it problem. First big problem is part A cares about border versus USA Canada. Part B and C do not. Other problem part A is expecting to do an MST of all the vertices part C. I need an MST of just some of the vertices. So what most people end up doing is taking their part A code, copying it over to part C, maybe as a member function, and modifying, modifying it so that when it calculates distance, it uses a helper that doesn't care about border and Canada and USA, and make it able to do an MST of just some of the vertices, not all of the vertices. And you have to be really careful there because let's do a harder example. Let's say my path vector was, I didn't example up here, 052143, 052143, and my perm length is 2. I need the MST of those four vertices. These two are the fixed ones. These are the MST vertices. And if you're not careful, your project, your MST for part C, might always produce the MST of 2345 or 345 or 445. It might just always do the last three instead of the last three in the path vector. So it's really easy to have part A right and just sort of fail the hand off. It's like a relay race where you've got to hand the baton from one person to another. Even though you're both good at running races, you've got to also get good at that hand off. If the hand off doesn't work, we fail. So you've got to be careful about the hand off. Now another thing that is speed wise important is when we call promising, I don't want to do all of this work for the MST and the connecting edges if it would take longer than just finishing the TSP. So let's look at some numbers. So I'm going to say K is equal to the number of unvisitant, which is equal to path.size minus perm length. So when perm length is 2, path size is 6, 6 minus 2 is 4, there's 4 vertices that are unvisited. Okay, so I'm going to make a table here. Okay. And the time to do an estimate. So the time to do the estimate, well, we've got to do an MST of K vertices. MST is quadratics, that's K squared. K squared is the time to do the MST plus 2K. That's the time to check the connecting edges because I've got to check vertex 0, the first thing in the path versus the K unvisited. And I've got to check vertex 5, the last thing in the path versus all of the unvisited. So that 2K comes from K of them for the first vertex, K of them for the last vertex. So K squared plus 2K. And then what would be the cost to finish the optimal TSP would be K factorial. Now, let's look at some numbers here. When K is 1 versus when K is 10. So when K is 10, let's say there were 30 vertices to begin with, 20 of them are fixed. 10 are still up for grabs. I say, well, how long does it take me to do the estimate? 10 squared plus 20, 120. So it takes me 120 time to calculate the estimate. If I calculate the estimate and it says it's still promising, I still got to do the K factorial work. But 10 factorial is on the order of 3.6 million. Now, if I do the estimate and it says true, I've added 120 work. Not very noticeable. But if I do the 120 work and promising says false, I can skip the 3.6 million work. So it's a big savings. This is a savings. I want to do the estimate when K is 10. When K is 1, the estimate takes me K squared plus 2K is 3, finishing it would just be 1. That's a waste of time. Whoops, I didn't mean to star that. I meant to ask, exit. Don't do the estimate. K is small enough that I just want to finish the TSP. What about 2? 2 squared plus 2 times 2 is 8. 2 factorial is 2. This is a waste of time. Don't do the estimate. 3 would be 3 squared plus 6 would be 15 versus 6 waste of time. At 4, 24 versus 24, you say, hey, that's equal. Let's do it. But if I do the 24 work and it says it's promising, I still have to do 24 more work. So like now I could either do 24 if I just do the optimal or I could do 24 plus 24 if I do the estimate and it says true, waste of time. What about 5? Okay, 35 versus 120. Maybe. So if I do the estimate and it says true, I've increased my work by over 25% like 28% I've increased my work. But if it says false, I've saved myself like 85 work. I've saved about 3 quarters. That could go either way. What about 6? 48 versus 720? That's a win. So what this means is that when you start the promising function, calculate this value. If this value is small enough, promising returns true. It just says it looks good, keep going, keep doing what you're doing. So if the unvisited is small enough, return true and we'll save some time because we won't waste time calculating all these estimates when it would take us less time just to try the three factorial remaining permutations. Okay, so that's important for saving time also. Now what if you're getting wrong answers? If you're getting wrong answers, something must be wrong in your numbers. So remember what promising has to do. If we do the estimate, we've got to do the current cost plus R1 plus R2. And when I say R1 and R2 here, I mean R1 is the one that goes from 0 to the closest unvisited. R2 is the one that goes from the last thing in the fixed portion of the path to an unvisited. Plus the MST is that less than my best cost so far. And that's what promising function answers is that comparison. Now if you're getting wrong answers, then one of these numbers has to be wrong. If you're too slow, maybe one of these answers is wrong. I've seen people who are like, ah, Dr. Piappett, trying to fix this for like four days and I'm just over time, I can't figure out why. Like, did you do the debugging output that we told you? No, I'm getting right answers. I don't need debugging output. I ain't she humor me. Go do that. Five minutes later, they're like, oh my gosh, my R1 is always 0. If my R1 is always 0, then I'm always doing an underestimate and I'm saying that lots of things are promising that shouldn't be. So we gave you some files. As part of the sample files, there's something called sample, e, debug, output. .txt. And there's also one for sample f. If you look at them, they're actually identical. Sample e and sample f are the same coordinates just in different places. Now try both of these. And what the sample, e, debug output is going to tell you is a lot of the top part is introduction. It's going to talk about it. It's going to give you some code. It's going to basically give you code that will produce a table like the bulk of the sample e, debug, output is this big table of values. And so you're going to output a lot of stuff. You're going to output everything in the path vector. You're going to output what's in the perm length variable. You're going to output all of these values, the current cost R1, R2, the MST. And you're actually going to also print out the total of all of these because, hey, maybe you messed up the math somewhere. And then you're going to compare your big table of numbers to our big table of numbers. And that'll help you figure out where you went wrong. Like, oh my gosh, my R1 is sometimes zero. That's the problem. I'll go fix my code for R1. Or, hey, sometimes my MST is right and sometimes it's wrong. I got to go fix the MST. Or, hey, my current cost eventually becomes wrong. You got to go fix the current cost. So this will really, really help you if you're getting wrong answers, do the sample e, debug output. If you're over time, do the sample e, debug, output. And also try sample f. Talk to us after you've tried both because the difference is one of them is all in the USA. And the other one, I don't know which is which. One of them is all in the USA. And the other one has some USA in Canada. If you get different answers for them, it's because your part c is still using like border distance instead of any distance instead of generic Euclidean distance. So part b and c better be doing Euclidean distance. And if you get like one of these right and the other one wrong, that would be the reason. Now there's a couple things that you have to do to produce this table about. One is you got to add some code. Two, you've got to, so you've got to add some code in promise into print all these values. You've got to add some code in main to set up for printing all this stuff. You've got to start your path the same way we do. And if you look at it, it'll show you that our starting path is zero, one, two, three, blah, blah, up to 10. And our starting cost, I can't remember the number. But you've got to take these as your starting point. And this has to be your, this has to be what you've got. And also I gave you the cost has to be zero. Your best cost has to be the number that we say. So print cost has to be zero. Best cost has to be the value we say. I don't remember what it is. But if you don't do these things, you won't have the same starting point as us. So even if you have a different starting point for your current path, you've got to change it to this to do sample E debug output. The other thing you have to do to get the same stuff as us is you have to go disable this check. Because with this check, you'll chop out a 20 rows of the table and you won't know what went wrong. So you've got to disable that check. So there's a few things you've got to do to get this debugging working correctly. But it'll really help you decide where your problem is. Also like I said, use the Visualizer tool to help you look at it and see what it looks like. Okay, I think that's about everything I made in my notes. So good look on the project and if you're having trouble, we'll see you in office hours.