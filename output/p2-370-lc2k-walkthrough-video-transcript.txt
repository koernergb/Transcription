 Hey, welcome back to each 370 discussions. Today we're looking at Project 2, which is linking and functions in LCK. We're going to look at the motivation for why we're doing this project, and the practical walkthrough to go through the spec example. Then we'll do just a couple tips and tricks and things to make sure that we all can succeed on the project. As usual, I'd like to start off by showing these graphs. This is the score distribution for Project 2A from the winter 2023 term. As expected, you see that typical drop-off that we tend to see with these projects. So by howling it here, you can see the minimum baseline without a couple outliers. It comes down here. If the deadline was right here, even submitting just like three days before the deadline guaranteed, you know, a 60, except for a few unfortunate outliers. But moving on to Project 2L, this is the same from winter 2022 instead of winter 2023. The autograder fell apart during the winter 2023 term. Then one happened again though. We can see the exact same thing, but we see more outliers over here, because Project 2L is significantly more difficult than Project 1 or Project 2A. So it's a very difficult project, and so I suggest starting as early as possible so that we're still kind of above that curve there. Then if we look at Project 2C, which we didn't do in the winter 2023 term, but we last in fall 2021 or 2022, we can see the same thing, but a lot more zeros, even in this kind of general range here. So that's not very good. That means it's a very difficult project. And we'll see why as we go through these slides here. But Project 2C is definitely one that you have to start earlier because it's written and else to K, but once you get it, it starts to fall into place. So let's actually get into the project content. So Project 2 is all about linking and else to K, and we need to be able to link and else to K in order to support most functions that we might write in our source code. And so we'll go through how we link, how our functions will look like when we translate them to assembly. And so that will bring the entire project together. So let's start by looking at how we use source code in order to turn it into a execable. So for thinking about just regular C programs that we might write on our computer, maybe we're thinking about Eeks 280, some of our projects there. We tend to have source code spread out through a lot of different C files. So for that wasn't really true in Project 1, we had the separate C files that each turned into their own execable, but most of the time that's not the case. So if you think back to Eeks 280 and you think about the Euchar project, you probably had something along the lines of like Euchar.cpp. And there was probably some sort of like main or like a driver that allows you to play the Euchar game. And when we compiled those two together, that actually made the game. But if you took that same Euchar file and linked it with your tests file, that I remember what was called, you had a separate execable to test the functionality of all your different classes and things. So we didn't replicate all the Euchar code into both of those main files. We kept it in one source and then by combining that with two separate sources at different times, we were able to make a two different execables that partially showed the same source code. And so that is what is the main motivation behind linking because we want to actually be able to turn multiple source files into one execable and cut out a bunch of copying and pasting. So let's look at this little diagram here. In this diagram, we have three source files written in C. And in order to turn it into a binary, the first thing we have to do is compile. And whenever it compiles, it's going to turn into some representation of assembly code. So so far with LCHK, a lot of the compiling we've done has been by hand. So we say, translate this C code into LCHK and you've done that. And then once you get some sort of assembly code, after that, you could run that through your assembler. But in Project 1A, we went straight from the assembler to a machine code file that we could run on our simulator. But now we want to be able to combine multiple assembly files into one. And so we're going to add in an intermediate step. So that intermediate step is going to be creating an object file in an else scale, have the OBJ ending. And an object file is mostly machine code. You can see the ones in zeros here. But it contains some extra information that we'll take a look at that tells us how it can be interleaved with the other object files. And then finally, once we have the object files, we can link them all together, turn that into our executable, which in else scale will be a machine code file. And then we can run that on our simulator and actually run the program. So the benefits of this approach is that we don't have to replicate a lot of operations. So let's say that I have made an executable, I have this a dot out or whatever it might be called. And I find a bug in my y dot c file over here. Well, once I change that bug, it would be nice if I could change the minimal amount of things in my machine code in order to get my new version of the program up and running as quickly as possible. And so now that we've separated out into all these different steps, I don't have to repeat the recompilation and assembling of these other files. I can just take whatever object files I had before, then compile my change, the file, assemble, might change the assembly code to get an object file, and then link again and get the new machine code. So you may not have encountered programs so far where compilation takes a long time. But in other contexts, maybe in industry that you'll see someday, compilation can take a really, really long time. And so if we can minimize the steps that we have to do and just link everything at the end, then we've minimize that compilation time and we can maximize our efficiency in terms of being programmers. This is very important to us. So in order to link, we need to know a couple things about how our memory is laid out in our executable. And so this should be reviewed from Eeks 280, but different variables in our runtime environment are going to be mapped to different spaces in memory. And those are four main spaces. So we have our text, which just means instructions. So when you're thinking about how to get all of our instructions, the opcodes, all those things, turn into machine code. They spit out numbers at just the end, just numbers and binary. And you can see them in decimal after project 1A. And that would all make up the text section. Beyond that, we have the data section, which will include global data, static data, in LCTGK, that's going to be anything with a .fill. So all the .fill is going to be in the data section. And so far in LCTGK, we've seen how we can mix these sections a little bit. But for project 2, all of the instructions should come before all the . fills. So we can actually separate them into two different sections. So those are both defined inside the machine code file. But we also are able to use a whole bunch more memory when we're actually executing the program. And so the two primary sections in memory that we'll define at runtime will be the heap and the stack. So we won't see too much of the heap usage in LCTGK, because implementing malloc is tricky, I mean assembly code. But if you want to review some of that, you can look back at some of the lectures from 280 that go over dynamic memory. And C and C plus plus instead of malloc, we use new and delete and C we use malloc and free. But it's all doing the same thing on the heap. And then finally we have the stack, which we will see in LCTGK. And the stack will allow us to store a bunch of local variables. And one of the nice things about the stack is that it grows with how many function calls you do. So it can grow until you reach a leaf function. And then when you go back up your call tree, it'll shrink again, it'll grow. It'll be exactly the size that it needs to be in order to hold all the local variables, especially with recursive functions. That is very, very necessary because you can't store all the variables in one spot if you're using recursive function because you'll have multiple instances of those functions and all those local variables. And they don't need to go somewhere. So we're going to put them on the stack. Right? By the way, if you are downloading the project starter code, the 370 make file will take advantage of the idea that we talked about where we can delay or skip some of the steps in recompiling all the code. So if you want to take a look at how we might skip certain steps in LCTGK, you can take a look at what the make file is doing. All right. So in order to link, we do have to figure out a couple things. And these are the main functionalities that we're going to provide to make sure that all of our different functions work. So first one, we're going to make sure that all code can branch to any function. So functions are defined in multiple files. We need to be able to jump between files. So for your thinking about like a visual debugger, whenever you step into a function, it's going to go to a completely separate place in your source code. And so that might be in a different file. It might be in the same file, but no matter what, we need to be able to get to all of the functions. Next, we also need to be able to access global data that's defined in any file. So if we're thinking about like maybe share to arrays, these arrays that are shared between multiple functions, we might define it only in one file instead of making different copies and things. And so that allows it to be actually shared, but we need to make sure that all instructions that refer to that array that piece of data are all actually using the same data instead of using copies or something like that. And then finally, we want the output to be kind of similar to what we've done before. So like I said, our object files are going to be mostly machine code, and then they'll have some extra metadata so that you can edit that machine code in your linker and then produce more machine code at the end. So that's kind of the goal here. All right. So those sections in our memory mapping are going to directly correspond to our object files. And so our object files are going to follow some sort of layout. And in Linux, this layout is called ELF, which stands for executable and linkable format. And it has six main sections. Really, the last section isn't strictly required, the debug section. So that appears if you compile with dash G or dash G3, as we usually do in this class. So we're going to ignore the debug section for else to get and just focus on all the others. The first section is the header. And in else to get this will be just one line. So this says what the size of the other sections are in terms of lines. So once you have the header, then you can actually figure out to where the different sections, the other four sections begin and end. So the first of those next sections is the text. So once again, that's probably the memory mapping. That's all of our instructions. Then we have our data. So that's our dot fills. And because the stack and the heap are only generated at runtime, you might expect that the last two sections would be the stack and the heap that is not going to be the case. We are instead going to have two tables that are going to tell us how to edit the machine code in the text and data sections. So that the final executable actually has all the correct numbers and all the different pieces of text and data can refer to each other as this proper. So the symbol table is just going to be basically a list of global variables. And so those can be variables, those can be functions, those can be all sorts of things. And then the relocation table is going to tell us what addresses in these different text and data sections for multiple object files will need to be edited so that everything points where it's supposed to be. And so for this class, for else, we're going to include in the relocation table any load store or dot fill that refers to any label. And we need that because LW and SW, they're offset fields as well as the entire field of a dot fill are resolved with absolute addresses. And so for things like branches that are relatively address, we don't need to include a relocation because they already point where they're supposed to. And we'll see more exactly what that means as we go through the spec example. So our final product will kind of look like this. If we have two object files from two different C files, we would initially see like headers and four other sections. And then when we kind of intially leave them together and then use the symbol and relocation tables to update all the entries in those sections, we would get something that could look like either of these two things. And when we're looking at the project, we're going to impose an ordering on this. This is a really done with C, but whichever file comes first in your linker command, so we'll look at in a little bit, you'll have a linker and you'll have some object file, which everyone comes first, will be the first hex section that appears in the final machine code file, the final exactable. And we do that because in lcdk, you always start at pc0 when you begin your execution. Other iSays don't necessarily do that, so other iSays could produce either of these two options, but for this class and for this project, we are going to require that the main equivalent in an assembly code is the first object file that is passed to the linker. Let's look specifically at what exactly the symbol table contains. So the symbol table, like I said, is going to contain all global variables. So it's going to include global functions. And in lcdk, those are going to start with capital letters. So if I see the label five in lcdk, because it doesn't start with a capital letter, that's going to be a local. But if I see the label five with a capital F in lcdk, that's going to be global. And that'll be true for both data and functions. All right. And so if we're doing things in c, we could include a couple other stack variables in the symbol table. lcdk, we're not going to include just everything in the data section. We're only going to include the global labels. And so our format will look like this. So we'll have the label, which is just a string. And then we will have some sort of type. And so we're going to represent this with t, d, and u, t meaning that it's a label that's defined in the text section, d meaning that it's a label defined in the data section with the .fill, and u meaning unknown or undefined. So it's not defined in this file, but we saw it used in this file, some sort of global label that hasn't been defined. It was used by named in lw or sw.fill. So we're going to market with a u for the object file. And then finally, if it is defined, we're going to place a section relative address. So if we zero index both of our sections, so like the first line of text would be zero, we would just take that address and now go in our address offset over here. Or the very first .fill in our data section would have whatever the label is and then d and then zero, because we're zero indexing the data section as well. If it's undefined, then we'll always just put the zero into this address. All right, so moving on from the symbol table, we have our relocation table and the relocation table, while it will also include a couple strings that will represent different labels. Really, the focus of the symbol table is what instructions or directives need to be updated. And so the symbol table or sorry, the relocation table will contain three things. It'll have another section relative address, section relative, and once again, we'll just split up the text and data sections. If it's an LW or SW, it must be in the text section. So we'll just zero index figure out which line it on is on and then that will be our address. And then if it's a .fill, we'll count from the first .fill, which will be .fill number zero and then see which .fill it is and that will become our address. And then we'll actually say what of those instructions or . fills it is. And then we're going to contain the string of the symbol that is being used in that case. So one important thing to note is that this includes relocations for all types of labels. This doesn't just include global labels. We're going to include local labels as well. But whenever you see things like just constants, we're going to leave those out. This is only to relocate to labels. So let's go through some practice. We're going to first see how we would look at some C code and kind of generate the information in the object file for the C code. And then we'll look at the exact spec example in lc2k. So let's say that I have this main .c file and I see a couple things in here. We're going to go through three steps. We're going to memory map, main and one of the file and then we're going to find the symbol and relocation tables for them. So in order to memory map main.c, I'm just going to take every single variable or label that I see and I'm going to say what section in memory it would belong to. So let's see. So through. Well, I can tell that that's a function of some sort. So that will eventually go into the text section and we'll see in a minute this will actually be undefined when we create our object file. But we can kind of see from the C code that it's obviously going to be a function. So it will eventually go into the text section. A bar that's going to be a local variable, two foo. So that will go on the stack. So let's see. So we have text, stack. A global bar here as the name suggests is a global variable. So we're going to put this into the data section. Main another function. So go in text. I another local variable. So go on the stack. Let's see. We see just duplicates of foo and i down here in global bar. We see size of size of though isn't actually a function. That's more of a macro and C. So this isn't actually going to go anywhere. It's going to be this entire thing will be resolved to a constant. Maloc. That's another function. So that'll go in text. X. Now this is tricky. Maloc returns x. But x itself is a pointer to data on the heap. So x is going to sit in the stack of main. But whatever x points to will be the heap. And so we get our full memory mapping for all the data that we can see in this file. Let's try another one. So we have food out. See same as before bar. That's a function goes in the text. Food also function goes in text and value. That's a local variable. So go on the stack. And then we see foo static and foo static appears local. But it is static. And anytime you see the static keyword, that means two things. One is going to be in the data section of this file. But also it's only going to be accessible within this file. So the main dot c will not be able to access this food static. And so it will go in the dot full section, but it won't go in the symbol table. We'll see that eventually. All right. Then we have foo dynamic, which appears to be a local. So that'll go on the stack. Food static and food dynamic again, bar again, bar once again, we'll go in the text section. So I think we've done our entire memory mapping for this file as well. So now let's find the symbol table for main dot c. So let's see. So let's just start from the top. And we will only be looking at things that we just now identified as being in the text or data sections. Because locals, they will be on the stack. They will not be relocated. So let's see. So we saw that foo was a function. So it will be in the text section. But it isn't defined in this file. That's what the extra keyword means. It means it's defined somewhere else. We're just kind of declaring it so that we know how to use it in this file. So foo will be in the undefined type in our symbol table. And then we have global variable, which we said was in the data section. And it is defined here. We don't see the extreme keyword. And we're giving it an initial value, which will go into the data section. So global bar will be in the data section. And for now, instead of figuring out the exact address section relative, we might use line numbers. But we see that global variable is like the first element of data that we found in this file. So it's offset has to be zero. And note that your compiler might reorder things, depending on how it is set up. And so in that case, the compiler would edit the address to be whatever it's supposed to. Then we move on to main. Main is going to be in the text section. No other text things are defined in this file. So main is going to be the only function in the text section, which means that it's address and offset will definitely be zero relative to the beginning of the text section. Let's see. Other things, malloc is a built-in function, but it's still defined somewhere else. It's not defined in this file. So this will be undefined. And that fixes everything for this file. All right, let's move on to a foo. So foo has two functions defined in this file. We see foo and then bar. And let's refresh all the data section things that we saw. The only one we saw was foo static. All the others turned out to be local. So that means that foo will be in the text section. And it will be at offset zero, presumably a bar will be in the text section. And its offset will be zero plus whatever the size of foo is. And then foo stack is the only piece in the data section here. So we'll give it a data section type. And then it'll be at offset zero. And that will be everything. All right, now let's get to the relocation tables. So other things that we just identified in the symbol table. And really anything that will be loaded or stored, we are going to actually let me go back here. We are going to put that into the symbol table. One thing to note. And I breeze over this quickly, even though foo static is in the data section, because it's static, it won't always go into the data section. So it's quite possible that this would actually be cut out of the symbol table and just be relocated instead. It depends on the compiler. And the compiler was still unsure that no other files can reference this foo static. But note that it might be in there and it might not. In any way, I should have noted that it's a static. So that other files know not to relocate with it. All right, now moving on to the relocation table, we're going to take anything that we know to be in the text or data section. Anytime it's referenced, we will generate some sort of relocation for it. And so that's only going to happen for instructions or directives, right? And so I see no directives in here. It would be kind of tough to figure out anyway. But let's go through the actual C code in here. So in main, we set I to zero, but that's local. Then we call foo. And foo is somewhere else. When we turn main into an object file, we won't know where foo is. So foo definitely has to be relocated. So whenever I call a function, I'm going to use some sort of branch. And for functions, specifically, we're going to use a branch link because we want to be able to get back to the rest of main after we call that function. So foo, this function call on line nine, we'll have a branch link to foo. Same thing for line 10. Then on line 12, we're going to read or load global bar. And then on line 14, we are going to make another function call to malach. So our relocation table will look like this. So jump branch link and the same thing. And we'll just have that one load. So I've put in line numbers for now. This would actually be translated to whatever address the assembly code instructions for the branch link would be. But we don't know what type of optimizations our compiler might put on. We don't know what types of things the compiler is going to do with the C code yet. So that could be a whole bunch of different things. So for now, we'll just use line numbers. Looking at foo, we're just going to go through once again the C code. So you might see this to start off and say, oh, we are setting a foo static, which is in the data section to a value. And so we need to relocate it. It's actually not true. Whenever we have an initialization of a static or a global, it's not going to be processed as an instruction. It's going to be processed as a dot fill, a directive. And since we aren't setting foo static to some other like pointer and memory, we don't need to relocate that at all. It's just going to be a dot fill. So we're not going to put that in a relocation table. But here when we use foo static, both to load its value for the addition and then to store its value for the results, we are going to have to include foo static in the relocation table. So on line eight, we will have a load and we will have a store to foo static. And then we see that again on line 11 because we must first load foo static, place it into a register of the stack in order to pass it to bar. And then bar only uses local variables. So we're not going to relocate anything for bar. And we do also need to add in the relocation to do a branch link on line 11 to bar a jump. And so that's it for a relocation table. So that was generally easy to do in our C code. There are always a couple of caveats with the C code. I think else to decay has more defined rules, but looking at it in else to K is going to be a little bit more tricky. So we're going to walk through the spec example. We've given you two files in the spec example with the correct object file output. And so once we get the object file output, we'll also go through the correct machine code output from the linker so that we can understand this entire example. So let's break down the example from the beginning. So we need to be able to define all five of the sections that we talked about in the linkable format. And so I'll go ahead and show you this is what our main object file is going to look like except we're not going to include these things in parentheses. This is just to make it easier to read for now. But we can see that we will have the five sections. We'll have a one line header. And then however long the date of the instruction section is that's how many lines we'll have in the text section. Then we'll do the same for the data section, same for the symbol table and then the same for the relocation table. And so we can kind of see how all those things break up differently. Okay. So like I said, the header is going to be exactly one line and it's kind of tough to calculate at first. So this means that you might have to go through and generate the other sections internally in your assembler before you print out anything. So when you're doing your header, even though it looks like it comes first, you might think it's the easiest thing to do that might not be the case. So we need to be sure to have some internal structures in order to be able to generate that information first. So you might be wondering why is it important to have the header or why do we even have it? We need the header, especially for the first two sections because sometimes it's hard to tell just by looking at the machine code, which of these is supposed to be an instruction and which is supposed to be just a number or a variable for our use. And so we need these sections to actually figure out which is which so that we can edit the correct entries when we get to our linker. All right. So the text, like I said, is just going to be the translations of all the different instructions and this will be assembled identically to project 1a with one exception. Anything that is undefined will be resolved to zero temporarily. So in project 1a, we took any label. Let's look at five, for example, and we just find it's address and then we place that into the offset field. So here, let's see, the address of five would be six. And so this number here would be like 81006 in hex. So I placed that six in the offset field. But now, since sub-adder is a global and it's undefined, we don't know where it's going to go. We're just going to place it with a zero for now. So this would translate to 840000. So the offset field will be entirely zero for that sub-address. All right. Then the, and let me go back real quick, all the other instructions are going to be very straightforward because in this project, we're going to save that BQs can't branch to undefined global labels. So there's no change for BQ. And these other instructions that don't use labels at all, there's nothing to change. So these will be a symbol be exact same as project 1a. So you don't really need to worry about them. The dot fields will be very, very similar. In this case, we have just one. And if it's a dot field with a numerical value, once again, same as project 1a, it will just use that same numerical value. But if we have a label, we're going to treat it just like the offsets of one of our LWs or SWs. So if I had a like five dot fill sub adder, perhaps, I would just place a zero in there, where if it was like five dot fill five, I'd place a six because five is defined on line six. It's a pretty simple for that. Then we get to our symbol table. So the symbol table, after we looked at the C example, might seem kind of complicated to go through. But remember that the symbol table is just going to be a list of all of our global variables. And so looking at this file, we just need to highlight all of the global variables that we see. And remember those global variables could appear over here. They could be defined in the file, or they could be in this column. They could be used in that one. And in this case, the only one we see in this file is going to be this sub adder. So a couple of things about the symbol table, you don't want any duplicates in the symbol table. So if I were to see sub adder over here being used, but I also saw it over here, that would mean that it's defined. And so I wouldn't want to include twice. I wouldn't, especially, want to include it once is undefined and once is defined, I'd want to only place the defined version in our symbol table. But that's not the case. So we're just going to place one instance of sub adder u0 into our symbol table for this example file. Now let's move on to our other file. So looking at this other file, we don't see many global labels in this one either. But once again, we do see the sub adder. The difference between mean and sub one for sub adder is that sub adder appears in that label field. So it's not going to be an offset. It's not going to be used. It's actually going to be defined in this file. And so when we translate that into our symbol table, we're going to put the label name and then we'll have this section. It's a dot fill. So it'll be data. And then we number off all of our dot fills starting the first one was zero. So we figure out the section relative offset should be a one. And that's how we generate our symbol table. So one's again pretty straightforward. So a couple of questions. Why do we only put global variables into a symbol table? Well, the reason is because we will never need to relocate anything that's not a global variable and defined in a different file. So we will relocate local variables that are in the same file. But we never relocate local variables that are in a different file. And when I say local here, local in LCJK really means like static. So non global. Because locals, as we've seen so far, usually are placed in registers instead. So when I say local here, I mean, some sort of dot fill with a label that has a lowercase letter. But we will never need to relocate those in between files. So we don't need to put them in the symbol table. And we'll see when we go through the machine code example, how we can still relocate local variables within the same file without having them in the symbol table at all. All right, let's move on to the relocation table now. So in the relocation table, we will just list off all the instructions and dot fills except for beacuse that use a label. So if I look through main, I see two such examples. I see the LWs for five and some matter. And so I'm going to place those directly into my relocation table zero LW five one LW sub adder. And once again, these offsets come because we can zero index from the very first element of the text section and then generate section relative addresses for each of those LWs. So that's how we get the zero in the one. Looking at sub one, we can kind of scam through and see the same thing. So I see that that first LW is using negative one. And then now I have a dot fill that is also referring to a label. And it is a local label. But once again, it's still needs to be relocated. So I will zero index the text section like that. And then I'll see that the LWs that section relative address zero. So place that zero there. And then LW in the name of the symbol. And then I'll zero index my dot fills. And I'll see that the sub adder dot fill sub one is at section relative address one. So I will place a one in the relocation table entry. Once again, pretty straightforward. So the difference between the similar and relocation table, the symbol table, at least to generate it, we're looking at both columns. Right? We're looking at the left side for things that are defined. We're looking at the right side, sometimes for things that are defined, but also to catch that which is undefined. And in the relocation table, we are only looking at those right columns to figure out what is being used. And then we have generated our symbol and relocation tables. And once we get those sizes, we can go back and fill out the header and we have the entire thing. All right. So now let's take a look at how we would link these two things together. And I'm not going to go through the mathematical answers in great detail because that's probably the project. That's something that you're going to be doing. But I do want to show you what these things look like. So when we interleave the different sections, thinking back to one of those earlier slides, where we have all the text sections come in order and then all the data sections, a lot of that is just going to be copying over this machine code. So you can see most of the machine code is the same. There's only a couple lines that are different. That line's different. That line's different. Let's see. This line up here and this line up here are different, but all the others are the same. And so how did we know when copying over this machine code to change those lines specifically? Well, we got that because those are the lines that we're referred to in our relocation table. So if this is the main.as text, I look at my relocation table. It tells me that I need to relocate. Let's see. This one right here and this one right here. So I'm going to do some math in order to figure out what the final value should be. Let's see. The first one that was changed was this LW015. And so originally, the offset was 6. So in here, if we were to convert this text, this would be like 81006 in hex. But now looking at our new sections, we can see that this 5 has been moved down by 3, because 3 is the size of all the text sections that come after main, specifically just the 1 text section of sub 1. So this 5, now counting from the top, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. If we were to convert this into hex, we would see it comes out to 81009. So there's a difference of 3, because this 5 value was moved down by 3. For sub-adder, we weren't able to just shift it by some amount. Instead, we took the original offset, which was 0. The entire thing, I think, was 8400. And then we replaced this offset field with the new address of sub-adder. And so we could tell that by seeing that sub-adder belongs to sub 1's data section at section relative offset 1, then seeing that this section begins at address 10. So sub-adder must be at address 11. And then we could put 11, which would be B, into the offset field for that line of machine code. Then looking at this LW down here, negative 1, similarly, we see that it was shifted down to address 10. So the offset field of this one would be an hex 82008. So the offset would be A in hex. And then finally, a sub-adder in the original assembly code referred to sub 1. And sub 1 was a local. And it was in the text section originally. So the original offset, and the original value, we saw was 0. But because we know it's local, that 0, instead of referring to something that's undefined, actually referred to line 0 of the text section for that file. So now, line 0 of the text section for that file is right here at this 6. So the actual that field value is going to be changed to 6. And that is how we generate our linked file at the end. So I went through that pretty quickly. But the code for this is actually quite complex. So I think Project 2L is significantly harder than Project 2A. And so knowing exactly what's going on here and why, how the linker is identifying each of these things is very, very important. So to summarize, your job for Project 2L is to go through every entry in the relocation table and just change the offsets and values of the lines that it specifies. And so if you use the simple tables and the headers and some other structures that you'll define in the linker, you can correctly adjust every single line of machine code that needs to be adjusted. And then you're done. So just a couple of things to think through when you're trying to debug, you might ask yourself did you check your labels correctly? Did you handle local labels and their offsets correctly? Are your text and data sections combined and in the correct order? Did you make sure to check for errors? So like Project 1A, Project 2A and 2L will also have their own error checks that you will need to look at. So be sure to go over the spec because I don't want to go over there. The spec has a lot more to say about this project than I could go through in this time. And so make sure to always refer to the spec for correct details. If there's something unclear, be sure to ask on Piazza or ask us in office hours. So now let's move on to functions and this will build up the motivation for Project 2C. So let's say that I take that main.as file that we were looking at for the Assembler and linker and actually try to interpret some of what's going on. So I see that we're loading 5 into register 1, then we're loading some sort of address into register 4, and then I am jumping to that address with Jalar. All right, then I'm going to assume for now that after the Jalar, it's somehow going to return to this BEQ. And I know that that's probably a reasonable assumption to make because I'm storing the PC for this BEQ inside register 7 whenever I make that Jalar call. So let's say after the Jalar, it comes back, then it checks if our counter maybe some sort of variable that we initialize to 5 is now 0. And if it is, we exit. And if not, we're going to loop until that is true. So looking at this assembly code, I can translate it kind of into a mean pseudo-c file. So I have some function main, it's setting a register to 5, some local variable, and then I am calling a function, and I'm expecting that function to modify that local variable, and I'm going to keep calling that function until it's modified and turned into 0. That's basically what's going on in this assembly code. We know that we're going to link it with this sub 1 file, so I think this is sub 1.as. And my sub 1, I'm going to assume that this is a function of some sort, because I see that we're taking an address and placing that into a global variable. So sub-adders like a function pointer. And I see that sub 1, all it does is it loads negative 1 into register 2, it decrements whatever register 1 is, and then it jumps back to some return address that's in register 7. So if I can buy my understanding of these two files, I can kind of see that a mean is expecting sub 1 to decrement register 1, and sub 1 is doing exactly that before returning. So if I wanted to, I could combine this into one giant file, but I didn't. And so if you're ever testing projects 2a and 2l, and you want to double check to make sure that is correct, you can do some of these things by hand. So if I took this assembly code from a.n.as, and I split it up into the text section in the data section, and then I did the same for sub 1. So there's my entire thing, there's my text and data sections, and then I interleave them in assembly to where I have main text, sub 1 text, main data, and then sub 1 data. In a assembly code, then I could run it through project 1a, and then I would get some machine code, and this machine code should be exactly identical to the machine code that I got when running them separately through projects 2a and 2l. So that's kind of bringing it all together. This is why the link is so important, because if I have functions in multiple files, I get the exact same behavior as if I had linked them and put them all into one file. So if you're ever wanting to get checked your understanding of projects 2a and 2l, you can do exactly that. And so that means that for tests, maybe your tests from project 1a that were only one file that didn't need to link with anything, you should be able to run them through projects 2a and 2l at the exact same machine code, because it won't change the order. So if you have a main text and then a main data, well, we already know what this machine code is, so it should produce the exact same thing. So let's look at more of how we can implement these functions in lcdk. And so in order to do functions in lcdk, we have to have an accurate understanding of what our registers are doing. So look at this function here. This function, sub 1, is decrementing register 1 by 1. And we can kind of tell that mean is expecting register 1 to be decremented. But what if mean was using, let's say register 2 to hold something else important? Well, sub 1 over rights register 2 with the value negative 1. And so if we were to return back to main after that, a main would have no idea that things were changed. And it might have some unknown value, which would be negative 1, but not what main is looking for in register 2. So because all these different functions are sharing these registers, we have to come up with ways to make sure that we don't lose any data. So that is going to influence our ABI and caller and call these saves. So let's think about it with an analogy. So let's say that I'm doing my off of stars in the BBB Learning Center as I like to do. And I have four whiteboards in there and I'm using them for all different kind of important things. So let's say that I want to go to lunch and I have more office hours after lunch because your GSI has never stopped working. And we want to make sure that nothing on the whiteboards is lost. I have two options. And so these are going to directly correlate to caller and call these saves. My first option, which is going to be my caller save, is to get out my phone and take a picture of whatever is on the whiteboard so that if it's changed in the time that I go to lunch, whenever I come back, I can just copy it back from my phone to the whiteboard. So for making the analogy between these whiteboards and registers, whenever you have a fault, a caller function, that's about to hand off the simulation or the run time to some other function, whatever is in its registers that it needs to save, it needs to put it somewhere on the stack in memory, some other safe location that isn't going to be touched while that other function is going. So let's call our save. The other option would be a call these saves. And I could either assume that no one's going to change it while I'm gone, or I could write a little note on there that says, please leave it how you found it. And so at that point, the responsibility would be on whoever is there in the learning center in the time while I'm gone in order to make sure that everything is put back as it's supposed to be. And so this is similar to a call these save when we're thinking of registers, where whenever the caller function passes off the run time to some other function, that function means to restore the initial state for each of the call these save registers right before it returns. And so to complete the analogy, these whiteboards directly correspond to registers. And this is important because I could have a different policy and assumption for each of the whiteboards. I can say, for these two whiteboards, I'll do caller save. And for these two whiteboards, I'll do call these save. This is similar with registers. We don't have to have some global policy where every register is caller saved or every register is call these saved. We can do some mixing. And so we could say some registers are caller save, some registers are call these save. And that is exactly what the ABI is going to specify. So to recap, the caller save registers is where the calling function has the responsibility to save them. And so if we have something that we don't need on the white board or in the register, then there's no reason to save it. So we can have some easy optimizations with caller save registers. But in call these save registers, the responsibility is on a function to save whatever previous function had some data. So it doesn't know if that previous function, the caller function is actually needing that data. But the callee function is going to save it, no matter what, to make sure that there's no room for things to go haywire and break down. But at the same time, we do have some options for optimization with callee save registers because we only need to save a register if it's overwritten, meaning changed, or the values different. So going back to sub 1 here, notice how we never reference the values in registers 3, 4, 5. And so that means that we can leave those alone, even if they were callee save registers because we're not changing the values. When we return from sub 1, the state in those registers is exactly the same. And so we don't have to actually do the save by changing them in no way we've practically done the save instead. And so that provides us with the two optimizations we'll look in this class in order to do our caller and callee save registers. So we should be able to go through some C code, not just a similar code, and identify what variables might be caller or callee saved and what the actual cost of that would be. So remember when we're writing these functions, all of our local variables will either get put on the stack or into registers with priority going to registers. So we're going to go through each of these functions and kind of see how many stores or loads we might need to do if we are mapping these variables to registers and saving them across different function goals. So let's start with get one. We'll get one is only modifying one register and that would be the return register. And the return register always is going to be caller saved, but get one doesn't have to do the saving because it's not making any function calls itself. So there will be zero caller saves in this get one function. I then count to n, let's see. So count to n calls this function get one of which we just went over and it is going to get one n times. So that means that for all the variables that need to save that are going to be used after we return from get one, we're going to have a store load pair in the assembly code for each of those. So let's look at it. So if we were to call get one in this first iteration of the for loop and we assume that get one over writes all registers, then we would lose the values of some i and n. And we see that we will need those values later, especially when we do the sum equal and we come back to do our comparison at every iteration of the for loop. So we would insert three store load pairs one for each of those variables in order to make sure that this function will work properly if all registers are caller saved. Then looking at start, we see start calls count to n and let's see it passes i. And so all the variables that start uses are a, b, c, and i. We don't have any others. So let's say that we count or we call count in, it changes all registers. So we lose everything. What did we need to say for sure? Well, we need to save a and b because immediately after we return from count in, if count in modify the registers with a and b, we will get the wrong address over here. But that means that we don't need to save c because c is going to be overwritten by the add results, which means that whatever c was, at this time here before we call count to n, we're never going to use that value of c again. So this three that we initialize c2 is never actually read. So we don't need to make any saves for c. And then once again, we'll need to save i because after we do this addition, we'll go back up in the for loop to check i and we'll increment it first. In order to increment, we'll need to know what the value of i was before we call to count to n. So once again, we're going to have three pairs in here. And then finally, in main, let's see, so main calls start and after we call start, it's going to need the value of r. So if star over writes r, then it won't have the correct value. So we're going to have one pair here, one pair. So that's how many would actually appear in this assembly code. But the question of the real cost can also come from how many are executed. So to finish out this problem, we need to figure out how many times we are going to actually execute the instructions that will store and load these variables. So of course, starting at main, we'll do one, one there. And the main will call start. Start has a for loop that does three iterations and it's going to have three pairs every time. So that means we'll have nine total saves when we execute start. And then start will call count in of zero, one, and two. If count to n has three pairs every time it's going through an iteration of its loop. And it's going to go through zero, one, and two iterations. That means it'll have three iterations across all calls to count to n. And so that will give us another nine. So that means that the total number of saves will be 19. But the number of instructions inserted will be, let's see, one plus three plus three times two. So 14. Now let's look at the function as if everything was called these saved. So let's see. So we'll start again with get one. We see that get one. I will somehow return the value one. But return registers are always call our saves. So we're going to ignore that one. In x86, I think sometimes it has to return values on its stack instead. In which case, we wouldn't need any explicit saves of registers. So get one won't have anything. Then let's see. Count to n is going to at the very beginning of its code save the previous values of registers for all registers that it's about to use. And it's going to need registers in order to hold some i and n. So that means we're going to make three saves every time we enter count to n. And then we'll have three restores at the very end here. So three. And similarly, start will have to save registers in order to make space for variables a, b, c, and i. And so every time we call start at the very beginning, we are going to make four saves. And at the very end, we're going to have four loads to restore. And then finally, main, well, main is the top level function. And you might be thinking that we need to save once for r. But that's not actually the case because of main is the top function. There's no previous functions stuff to save. And so main is never going to make any call e saves. So we'll insert a total of seven pairs, which was actually the same as in our assembly code for the call error save registers. We'll insert seven pairs of loads and stores. But the actual execution will be different. So when we call start, we will do four, loads and stores. And so we won't do those inside the for loop. We'll do that outside the for loop. And then we'll call count to n three times. And we don't need to know the exact number of iterations inside count to n because now count to n also is doing its stores and restores outside of that for loop. So then we'll call count to n three times. And it'll do three stores every time. So we will get a total of 13. 13 saves executed across the lifetime of the program. So let's see. So let's see if we can take advantage of some of these optimizations that we know. So we saw that with the caller save registers, we had 19 saves executed with the call e save registers. We executed 13 and we didn't do any for main. So let's see if we can find some optimal set of registers such that we can minimize the number of saves that we do. So let's say that we have three caller save registers and three call e save registers. We're going to go through each function. And based on our previous counts, we will see how many saves we did per variable. And then whichever of caller call e was better for that variable, we'll assign that variable to that type of register. So once again, get one did none. Whenever we executed count to n, we did a couple of different things. So let's see. Let's go back to our caller saves. Whenever we did count to n, we could do anywhere between 0 and 6 saves for every variable. So we don't really know. Let's see here. We did nine for caller and then nine for call e. So that means it's really not going to matter what we do for our caller or call e registers. No matter what, it's going to come out to nine for all the variables in count to n. All right, then we'll look at start. So let's see, going back in start, we did four saves for call e. And then we did nine saves for caller. One of the thing is that the granularity was a little different because remember that in caller, we never saved for C. So if we can assign C to a caller save register, that means that we will never use any saves for C. But between all the others, we did nine for AB and I in caller and only three, or sorry, yeah, three for AB and I in call e. So we can assign AB and I to call e and that will allow us to minimize the number of saves. And then once again, R, we minimize whenever it was call e. So we'll do zero for R. So that's execution. Once again, the actual instructions would be inserted here for call e to wrap the function. And then for a caller, it would wrap the function call that's being made. But the execution is going to be maximized with this setup here. So I mentioned just now that the instructions are going to wrap different things depending on if it's a caller save or call e save. We'll look at how to implement that in LCK in just a minute. So this is all going to feed into project 2C. This is the motivation for project 2C. Because in project 2C, we're going to write a recursive function in LCK that will do the combination. And so if you're familiar with the combination, there's a couple different ways to calculate it, but one way to calculate it is recursively. So if we have combination in of R, that means how many combinations can we generate among in items by choosing R of those items? How many unique combinations can we get? We can define that with this recursive function. So if R is zero or in is equal to R, well, of course, there's only one combination possible. Because you only have one possible combination of zero things. And if you have in things, then there's only one possible combination of in things, because you can't choose like more than in things. But for anything else, we can calculate it by adding up a combination within minus 1 in the same R and then in minus 1 and R minus 1. If we take those two, we will get different combinations. All right. So once you write this function in LCK, you are going to link it with a common main LCK file that we'll provide you in StarCode. And so the idea is to run project 2A on both of those and then use project 2L to link them and then use your project 1S to run it and see if it outputs the correct value for the combination. So much like project 1M where we have like M-CAND.Fill and it was a number and we did the same for implier. We are going to have the starting in and R defined also in a .fill. And then in main, it will load it and then it will call your combination function. And your combination function should put the correct answer into register 3. And so one of the very tricky things about this project is to allocate our caller and callee save registers. And so we provide, we'll look at it in the next slide like a basic API. But this is really, really important, like I said, for recursive functions because we have multiple calls of these recursive functions among our call tree. So for example, we'll have, let's say, 7-3, we're making that combination. And then com 7-3 in doing this addition, we'll have to make a function call of com 6-3 and then 6-2. These are separate function calls. And all of them will have their own variables. So they'll all be like in and R and other things you might define. But they're all different copies. Each of them belongs to a different one of these calls. And so we have to allow them all to be in our system at the same time. And so we're going to use the stack to save all that. And so our caller and callee saves will temporarily save things to stack and then restore them to registers in order to make sure that we don't lose any data. So this is the ABI that we're going to ask you to use for project 2C. And generally all else 2K functions should follow this. So an ABI, I remember, is different from an ISA, although they are very close to linked. So an ABI is just an agreement between all the different functions in an ISA to use registers for the same purposes. And so you're going to have to fill in the rest of this ABI to make sure that it is actually usable in your combination function and is also optimal. So as we just saw, picking caller or callee for your registers can induce more fewer loads in stores. And so it's up to you for each of these registers that can be either in order to you have to figure out which would be optimal. Caller or callee, and then you use that every time you make these function calls. So let's go through this. So in the else 2K ABI, register 0 should always be 0. Because remember that's not something that's enforced by the ISA. We can technically modify register 0, although it makes things not work. So the whole idea of the ABI is that we want everything to work. And then registers 1 and 2 are going to be the arguments. So whenever we make the function call, whatever in and R need to be, they should be placed in registers 1 and 2 respectively. So this is kind of what we saw in the translation of the spec example for project 2A and 2L. You may have noticed that when I placed in the sub 1 function, I passed the argument R1 to sub 1. That's because sub 1's first argument here is register 1. And so in else 2K, the first argument should always be register 1. And then the second argument will always be register 2. The return value in else 2K should always be in register 3. So whenever you call 1 0 for example, the return value should be in register 3, which in this case would be 1. Then we have register 4, which is scratch register same as register 6. We have register 5, which is a stack offset pointer. And we'll look at that in a second. What exactly that means? That means that it's global. So it's not saved to the stack. It actually defines how we save to the stack. So all the functions are going to share it. And then register 7 should be a return address. So if we look back at that example again, we saw that register b when we did our function call was register 7. But when we return from the function, register a was register 7. So the return address register is going to be used in that way to both make calls and returns and make sure that we go to the same place all the time. So let's look at an example of how we would use this ABI to actually make these saves to the stack. So I have this problem. I want to convert this function to else decay using that ABI. And we're going to do it with two versions. First, we're going to do it with register 1, caller saved, and then call e saved. And we're going to use a caller save register 6 for a junk value of the jaylor. So we'll see what that means. So first, let's ignore all the saves and just convert this assembly code into assembly. So we see that we're setting the variable a to 1. When else, okay, we know how to do that. And that's pretty easy. We just have an LW to a register and we set it to 1. Then we want to do our function call. And so we want to pass a as the first argument to the function. And so that's why I would pick register 1 in this case. Then I need to load a function pointer. And as we saw in the example, a function pointer is kind of like a two-step process. So the offset of our load will refer to the actual pointer. And then the pointer will be a dot fill that contains the start PC of the function. And so it's a mystery right now. But if we look back, we can kind of see how we do this. So we had a sub adder right here. And then that was actually defined in another file. But this sub adder, a dot filled with sub 1, which resolved eventually after linking to the PC of this function, sub 1. And so that's how we can load it into the correct register so that we can jump to it with jailer. So we loaded into register 6. Then we jumped to it from register 6. And we store the PC of the next instruction into register 7. So we assume whenever we're doing an ABI that the calle function will also fall the ABI. So we are assuming that after we make this jailer call, the mystery function is going to have a jailer where register a is 7. And so come back right to the next instruction after jailer. And so we will continue that. We need to increment a by mysteries return value. We know that the return value should be in register 3. So I'll add registers 1 and 3, place it back in register 1. And then start also needs to return to whatever function called it. So the function that called it was also being the ABI and put its return address into register 7. We are going to have a jump that goes to register 7. And because jailer can't just store PC plus 1 to nowhere, we have to pick a register to store it into. And so we're going to pick a register 6 to do that. Since it's already a scratch register, we don't need this value of f call anymore. And so that's everything with this function. Now we have to turn it into a proper function that will use caller and calle stores. So our caller saves, as I said with our C code example, will always insert the loads and stores to wrap the function call. So our function call is this right here, this is simply code. And so notice how this pink code, all these loads and ads and stores are going to wrap that function call. So in order to actually do the stores, we need to save it onto the stack. And so the stack in LCTK and in project 2C is going to be initialized at the very end of all the text and data sections from our link to executable. So the starting address of the stack is going to be right here. And so in LCTK, we're going to implicitly define a stack label that your linker should resolve to whatever this addresses. So the stack should point here. And then the stack we're going to allow to grow down. So that means every address after that is going to be permitted to be used as part of the stack. And so in order to track where we are in the stack at any given time, we're going to use a stack pointer. So the stack pointer is officially going to be defined as stack, meaning the address that the stack label is resolved to plus the value in register 5. So register 5 will start at 0. So that means that the stack pointer will start here. And then every time we want to move the stack pointer, instead of moving the stack, we can just increment register 5. So let's look at the actual saves. So we are going to save whatever register we need to, it will be 7 onto the stack. And then we are going to increment register 5 by loading the value 1 into a scratch register. And then adding that scratch register with register 5 in order to increment the stack pointer overall. And then we'll do that again with register 1 and add once again. Then we make our function call everything is stored to the stack. So that once we return, we can do everything in reverse to pull these values. So this might be like register 7 and register 1 back off the sack into our registers. So in order to do that, we need to decrement the stack pointer, which is the opposite of this increment here. And so we'll do that by loading the 1 into a scratch register once again adding that with the sack pointer. Then doing the opposite of a store, which is a load. Then doing the opposite of another increment, which is a decrement. And then finally the opposite of a store, which is another load. And now we've moved everything back from the stack to our registers. So this means that whatever value is in register 7 and 1 at this point, is going to be the same value in register 7 and 1 at this point. We have preserved all the important data. So that's how we would do caller saves in assembly. Now let's say that we wanted to do call eSaves. We'll call eSaves like I said before. Instead of wrapping the function call, we'll wrap the entire code of the calle function. So look at these green comments that I have here. They wrap the entire code that makes up the start function. And the cool thing about the calle stores is that it's going to be the exact same assembly code as the caller saves. So all we have to do is move that white code from the outside to the inside so that now the saves wrap the entire function code. They said just that one function call. And we're done. Absolutely it. So notice that everything is still in reverse order. So we still have the reverse increment and decrement, reverse load and store, another reverse increment and decrement, and another reverse load and store. And note also that the order of the registers is also reversed. So if we saved one last, then we are going to restore one first. And if we saved seven first, we're going to restore seven last. So as long as we do everything in opposite, whatever values were in registers at this point will be the same values in the registers right before we return. So whatever function called start will have the exact same state as it did when it called start. So that's everything for this project. We went through 2A, 2L and 2C. So I didn't give you everything for the project, but this should be enough to get going. And so good luck on the project and see you next time.